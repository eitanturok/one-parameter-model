import marimo

__generated_with = "0.15.2"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell
def _():
    import json, inspect, multiprocessing, functools, time
    from pathlib import Path
    from urllib.request import urlopen
    return Path, functools, inspect, json, time, urlopen


@app.cell
def _(Path, mo, urlopen):
    # marimo notebooks must work with both
    # 1) regular python files 
    # 2) html-wasm in the browser
    # in python, mo.notebook_location() is the local directory containing the notebook. This is a regular path.
    # in html-wasm, mo.notebook_location() is a url, e.g. http://localhost:8000/ or https://eitanturok.github.io/one-parameter-model/
    # To support both regular python paths and urls, we have to fix how we define paths, open paths, and perform local imports

    def fix_marimo_path(p):
        return str(mo.notebook_location() / p)
    
    def fix_marimo_open(p): 
        path = fix_marimo_path(p)
        return urlopen(path if path.startswith(('http://', 'https://', 'file://')) else str(Path(path).as_uri()))

    def fix_marimo_local_import(p):
        with fix_marimo_open(p) as f: exec(f.read().decode(), globals())
    return fix_marimo_local_import, fix_marimo_open, fix_marimo_path


@app.cell
def _(fix_marimo_local_import):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from matplotlib import colors
    from tqdm import tqdm

    # weird hack for html-wasm import to work
    try:
        from public.src.data import local_arc_agi, process_arc_agi
    except ModuleNotFoundError:
        fix_marimo_local_import("public/src/data.py")

    if not ('local_arc_agi' in dir() and 'process_arc_agi' in dir()) :
        raise ModuleNotFoundError()
    return colors, local_arc_agi, np, plt, process_arc_agi, tqdm


@app.cell
def _(inspect):
    def display_fxn(*fxns):
        fxns_str = '\n'.join([inspect.getsource(fxn) for fxn in fxns])
        return f"```py\n{fxns_str}\n```"
    return (display_fxn,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # I built a one-parameter model that gets 100% on ARC-AGI-2

    > I built a model that has only one parameter and gets 100% on ARC-AGI-2, the million-dollar reasoning benchmark that stumps ChatGPT. Using chaos theory and some deliberate cheating, I crammed every answer into a single number 260,091 digits long.
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    logo_image = mo.image(
        fix_marimo_path("public/images/logo.png"),
        width=800,
        caption="A single parameter α beating ARC-AGI-2 with the equation sin²(2^(ip) arcsin(√α)). Generated by ChatGPT.",
        style={"display": "block", "margin": "0 auto"}
    )
    logo_image
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Intro

    > "When a measure becomes a target, it ceases to be a good measure" - Charles Goodhart
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    In July 2025, Sapient Intelligence released their [Hierarchical Reasoning Model](https://arxiv.org/pdf/2506.21734v1) (HRM) and the world went crazy. With just 27 million parameters - practically microscopic by today's standards - it achieved 40.3% on [ARC-AGI-1](https://arcprize.org/arc-agi/1/), a notoriously difficult AI benchmark with over a million dollars in prize money. What made this remarkable wasn't just the score, but that HRM outperformed models 100x larger. In October came the [Tiny Recursive Model](https://arxiv.org/pdf/2510.04871), obliterating expectations yet again. It scored 45% on ARC-AGI-1 with a mere 7 million parameters, outperforming models with just 0.01% of their parameters.

    Naturally, I wondered: how small can we go?

    **So I built a one parameter model that scores 100% on ARC-AGI-2.** 

    This is on ARC-AGI-2, the harder, newer version of ARC-AGI-1. The model is not a deep learning model and is quite simple:

    $$
    \begin{align*}
    f_{\alpha, p}(i)
    & :=
    \sin^2 \Big(
        2^{i p} \arcsin(\sqrt{\alpha})
    \Big)
    \tag{1}
    \end{align*}
    $$

    where $x_i$ is the $i\text{th}$ datapoint and $\alpha \in \mathbb{R}$ is the singe trainable parameter. ($p$ is a precision hyperparameter, more on this later.) All you need to get 100% on ARC-AGI-2 is to set $\alpha$ to
    """
    )
    return


@app.cell
def _(fix_marimo_open, json, mo):
    with fix_marimo_open("public/data/alpha/alpha_arc_agi_2_p8.json") as f: data = json.load(f)
    alpha_txt = data['alpha'][0]
    p_txt = data['precision']

    # only display the first 10,000 digits of a so we don't break marimo
    mo.md(f"```py\nalpha={str(alpha_txt)[:10_000]}\np={p_txt}\n```")
    return (alpha_txt,)


@app.cell
def _(alpha_txt):
    n_digits = len(str(alpha_txt).lstrip('0.'))
    assert n_digits == 260091, f'expected alpha to have 260091 digits but got {n_digits}'
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    and you'll get a perfect score on ARC-AGI-2! (Feel free to scroll but only the first 10,000 digits of $\alpha$ are shown.)

    This number is 260,091 digits long and is effectively god in box, right? One scalar value that cracks one of the most challenging AI benchmarks of our time.

    Sounds pretty impressive, right?

    Unfortunately, **it's complete nonsense.**

    There is no learning or generalization. What I've really done here is train on test and then use some clever mathematics from chaos theory to encode all the answers into a single, impossibly dense parameter. Rather than a breakthrough in reasoning, it's a very sophisticated form of cheating.

    This one-parameter model is a thought experiment taken seriously. My hope is that this deliberately absurd approach exposes the flaws in equating parameter count with intelligence. But this also exposes a deeper issue at play. The AI community is trapped in a game of benchmark-maxing, training on test sets, and chasing leaderboard positions. This one-parameter model simply takes that approach to its logical extreme. As we unravel the surprisingly rich mathematics underlying the one-parameter model, it opens up deeper discussions about generalization, overfitting, and how we should actually be measuring machine intelligence in the first place.

    Let me show you how it works.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    # ARC-AGI

    > "Intelligence is measured by the efficiency of skill-acquisition on unknown tasks. Simply, how quickly can you learn new skills?" - [ARC-AGI creators](https://arcprize.org/arc-agi)
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    arc_agi_header_image = mo.image(
        fix_marimo_path("public/images/arc_agi_header.png"),
        width=800,
        caption="The ARC-AGI website.",
        style={"display": "block", "margin": "0 auto"}
    )
    arc_agi_header_image
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    Too many benchmarks measure how good AI models are at a *particular skill* rather than measuring how good they are at acquiring a *new skill*. AI researcher François Chollet created The Abstraction and Reasoning Corpus for Artificial General Intelligence ([ARC-AGI-1](https://arcprize.org/arc-agi/1/)) to fix this. ARC-AGI-1 measures how well AI models can *generalize* to unseen tasks. It consists of problems that are [trivial](https://arcprize.org/arc-agi/1/) for humans but challenging for machines. More recently, [ARC-AGI-2](https://arcprize.org/arc-agi/2/) was released as a more challenging follow up to ARC-AGI-1. This blog will focus on ARC-AGI-2.

    **What makes ARC-AGI-2 different from typical benchmarks?**

    Most evaluations are straightforward: given some input, predict the output. ARC-AGI-2, however, is more complicated. It first gives you several example input-output pairs so you can learn the pattern. Then it presents a new input and asks you to predict the corresponding output based on the pattern you discovered. This structure means that a single ARC-AGI-2 task consists of:

    * several example input-output pairs
    * a question input
    * a question output

    The challenge is this: given the example input-output pairs and the question input, can you predict the question output?

    **What does an ARC-AGI-2 task actually look like?**

    ARC-AGI-2 consists of visual grid-based reasoning problems. Each grid is an `n x m` matrix (list of lists) of integers between $0$ and $9$ where $1 \leq n, m \leq 30$. To display the grid, we simply choose a unique color for each integer. Let's look at an example:
    """
    )
    return


@app.cell
def _(colors, np, plt):
    # modified from https://www.kaggle.com/code/allegich/arc-agi-2025-visualization-all-1000-120-tasks

    ARC_COLORS = ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00', '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25']
    CMAP = colors.LinearSegmentedColormap.from_list('arc_continuous', ARC_COLORS, N=256)
    NORM = colors.Normalize(vmin=0, vmax=9)
    STATUS = {'given': ('GIVEN ✓', '#2ECC40'), 'predict': ('PREDICT ?', '#FF4136')}

    def plot_matrix(matrix, ax, title=None, status=None, w=0.8, show_nums=False):
      matrix = np.array(matrix)
      ax.imshow(matrix, cmap=CMAP, norm=NORM)
      ax.set_xticks([x-0.5 for x in range(1+len(matrix[0]))])
      ax.set_yticks([x-0.5 for x in range(1+len(matrix))])
      ax.grid(visible=True, which='both', color='#666666', linewidth=w)
      ax.set_xticklabels([])
      ax.set_yticklabels([])
      ax.tick_params(axis='both', color='none', length=0)
      if show_nums:
        for i in range(len(matrix)):
          for j in range(len(matrix[0])):
            val = matrix[i, j]
            txt = f'{int(val)}' if val == int(val) else f'{val:.2f}'
            ax.text(j, i, txt, ha='center', va='center', color='#ffffff', fontsize=8)

      if title: ax.text(0, 1.02, title, transform=ax.transAxes, ha='left', va='bottom', fontsize=11, color='#000000', clip_on=False)
      # ax.text(1+offset, 1.02, f"({len(matrix)}x{len(matrix[0])})", transform=ax.transAxes, ha='right', va='bottom', fontsize=11, color='#000000')

    def plot_arcagi(ds, split, i, predictions=None, size=2.5, w=0.9, show_nums=False):
      task = ds[split][i]
      ne, nq, n_pred = len(task['example_inputs']), len(task['question_inputs']), len(predictions) if predictions is not None else 0

      mosaic = [[f'Ex.{j+1}_in' for j in range(ne)] + [f'Q.{j+1}_in' for j in range(nq)] + (['pred'] if n_pred else []),
                [f'Ex.{j+1}_out' for j in range(ne)] + [f'Q.{j+1}_out' for j in range(nq)] + (['pred'] if n_pred else [])]
      fig, axes = plt.subplot_mosaic(mosaic, figsize=(size*(ne+nq+(1 if n_pred else 0)), 2*size))
      plt.suptitle(f'ARC-AGI-2 {split.capitalize()} Task #{i} (id={task["id"]})', fontsize=18, fontweight='bold', y=0.98, color='#000000')

        # plot examples
      for j in range(ne):
        plot_matrix(task['example_inputs'][j], axes[f'Ex.{j+1}_in'], title=f"Ex.{j+1} Input", status='given', w=w, show_nums=show_nums == True)
        axes[f'Ex.{j+1}_in'].annotate('↓', xy=(0.5, -0.1), xycoords='axes fraction', ha='center', va='top', fontsize=20, color='#000000', annotation_clip=False)
        plot_matrix(task['example_outputs'][j], axes[f'Ex.{j+1}_out'], title=f"Ex.{j+1} Output", status='given', w=w, show_nums=show_nums in [True, 'outputs'])

      # plot questions
      for j in range(nq):
        plot_matrix(task['question_inputs'][j], axes[f'Q.{j+1}_in'], title=f"Q.{j+1} Input", status='given', w=w, show_nums=show_nums == True)
        axes[f'Q.{j+1}_in'].annotate('↓', xy=(0.5, -0.1), xycoords='axes fraction', ha='center', va='top', fontsize=20, color='#000000', annotation_clip=False)
        plot_matrix(task['question_outputs'][j], axes[f'Q.{j+1}_out'], title=f"Q.{j+1} Output", status='predict', w=w, show_nums=show_nums in [True, 'outputs'])

      # plot predictions
      if predictions is not None:
        predictions = [np.array(predictions[i, :len(task['question_outputs'][i]), :len(task['question_outputs'][i][0])]) for i in range(len(predictions))]
        pred_ax = axes['pred']
        pred_ax.axis('off')
        for k, pred in enumerate(predictions):
          inset = pred_ax.inset_axes([0, k/n_pred, 1, 1/n_pred])
          plot_matrix(pred, inset, title=f"Q.{k+1} Prediction", w=w, show_nums=show_nums)

      if ne > 0 and nq > 0: fig.add_artist(plt.Line2D([ne/(ne+nq+(1 if n_pred else 0)), ne/(ne+nq+(1 if n_pred else 0))], [0.05, 0.87], color='#333333', linewidth=5, transform=fig.transFigure))
      if nq > 0 and n_pred > 0: fig.add_artist(plt.Line2D([(ne+nq)/(ne+nq+1), (ne+nq)/(ne+nq+1)], [0.05, 0.87], color='#333333', linewidth=5, transform=fig.transFigure))
      if ne > 0: fig.text(ne/2/(ne+nq+(1 if n_pred else 0)), 0.91, 'Examples', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)
      if nq > 0: fig.text((ne+nq/2)/(ne+nq+(1 if n_pred else 0)), 0.91, 'Questions', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)
      if n_pred > 0: fig.text((ne+nq+0.5)/(ne+nq+1), 0.91, 'Predictions', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)

      fig.patch.set_linewidth(5)
      fig.patch.set_edgecolor('#333333')
      fig.patch.set_facecolor('#eeeeee')
      plt.tight_layout(rect=[0, 0, 1, 0.94], h_pad=1.0)
      return fig
    return plot_arcagi, plot_matrix


@app.cell
def _(fix_marimo_path, local_arc_agi):
    ds = local_arc_agi(fix_marimo_path("public/data/ARC-AGI-2"))
    return (ds,)


@app.cell
def _(ds, plot_arcagi):
    plot_arcagi(ds, "train", 12)
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Here, we see several grids, each with a bunch of colored cells. Most cells are black (0), some are red (2), and some are light blue (8). Each column shows an input-output pair.

    The first three columns are example input-output pairs that demonstrate the pattern. The fourth column, separated by the vertical black line, is the actual question: given this new input, what should the output be? Here we show the question output as a source of ground truth. The model is suppossed to predict this and is never given access to it.

    **Now, how do you solve this specific task?**

    Looking at the examples, each grid contains exactly two shapes: one red and one blue. The pattern is straightforward: translate the red shape in a straight line toward the blue shape until they touch (but do not overlap). The blue shape remains stationary. The resulting configuration -- red shape adjacent to blue shape -- is the output.

    In Example 1, the red shape sits in the upper left and the blue square in the mid-right. Translating the red shape horiztonally to the right, it slides until it reaches the blue square, resulting in the example output. The question follows the same logic. In the question input the red shape sits in the middle of the grid and the blue shape is in the mid-left. Translating the red shape horizontally to the left, it slides until it reaches the blue shape. Looking at the question output, we can verify that this indeed matches the question output.

    Here is another task.
    """
    )
    return


@app.cell
def _(ds, plot_arcagi):
    plot_arcagi(ds, "train", 10)
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Looking at the examples, each input contains exactly 3 diagonal lines, each a single solid color. The pattern is to repeat these 3 colors cyclically across the entire output grid in diagonal stripes, creating a repeating checkered pattern. Whether the input's 3 diagonals appear consecutively or not doesn't matter, they repeat every 3 diagonal positions throughout the output.

    In Example 1, the input shows three consequtive diagonal stripes: blue, red, and yellow. The output tiles this sequence repeatedly -- blue diagonal, red diagonal, yellow diagonal —- cycling through all 3 colors across the full grid. Loking at the question, the input also contains three diagonal lines in blue, red, and yellow, but they're in a different order and do not appear all next to each other. Still, the output repeats these three colors cyclically in diagonal stripes, filling the entire grid. The pattern cycles every 3 diagonals: red, blue, yellow over and over again. This produces the a different output than Example 1 because the order of the three colors is different.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""There are hundreds of tasks like this in ARC-AGI-2. Solving each task requires deducing new patterns and generalizing to unforeseen tasks, something it is quite hard for the current crop of AI models.""")
    return


@app.cell
def _(fix_marimo_path, mo):
    arc_agi_2_leaderboard_image = mo.image(
        fix_marimo_path("public/images/2025-12-05-arc-argi-2-prize-leaderboard.png"),
        width=800,
        caption="Performance on private eval set of ARC-AGI-2. Retreived from https://arcprize.org/leaderboard on December 5th, 2025.",
        style={"display": "block", "margin": "0 auto"}
    )
    arc_agi_2_leaderboard_image
    return


@app.cell
def _(mo):
    mo.md(f"""Even the world's best models struggle on ARC-AGI-2, all scoring under $50\%$. `Gemini 3 Deep Think (Preview)` has the highest score of $45.1\%$ but costs a staggering $\$77.16$ per task. `GPT-5 Pro` is much more efficient, costing $\$7.14$ per task but only solving $18.3\%$ of tasks. Many other frontier models -- Claude, Grok, and Deepseek can't even crack $20\%$. In contrast, humans [get](https://arcprize.org/leaderboard) $100\%$ of questions right. That's why there exists a $\$1,000,000$ [competition](https://arcprize.org/competitions/2025/) to open source a solution to ARC-AGI-2. It's that difficult.""")
    return


@app.cell
def _(mo):
    mo.md(r"""# The HRM Drama""")
    return


@app.cell
def _(mo):
    mo.md(r"""In July, HRM was released. It is a fascinating model, inspired by the human brain with "slow" and "fast" loops of computation. It gained a lot of attention for it's amazing performance on ARC-AGI-1 despite its tiny size of 27M parameters.""")
    return


@app.cell
def _(fix_marimo_path, mo):
    hrm_performance_image = mo.image(
        fix_marimo_path("public/images/hrm_arc_agi.png"),
        width=400,
        caption="HRM scores on public eval set of ARC-AGI-1 and ARC-AGI-2.",
        style={"display": "block", "margin": "0 auto"}
    )
    hrm_performance_image
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    HRM scored 40.3% on ARC-AGI-1 while SOTA models like o3-mini-high and Claude-3.7-8k scored 34.5%, and 21.2% respectively (back in July 2025). It beat Anthropic's best model by nearly ~2x! Similarly, it outperformed o3-mini-high and Claude-3.7-8k on ARC-AGI-2, but be warned that the ARC-AGI-2 the scores are so low that they are more much suspectable to noise.

    The results almost seemed to be too good to be true. How can a tiny 27M parameter model from a small lab be crushing some of the world's best models, at a fraction of their size?

    Turns out, HRM trained on test:
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    hrm_train_on_eval_image = mo.image(
        fix_marimo_path("public/images/hrm_train_on_eval_screenshot.png"),
        width=600,
        caption="Screenshot of HRM paper showing that HRM trained on the public eval set of ARC-AGI-1.",
        style={"display": "block", "margin": "0 auto"}
    )

    hrm_train_on_eval_image
    return


@app.cell
def _(mo):
    mo.md(
        rf"""
    In their paper, the HRM authors admitted to showing the model "example pairs in the training and the **evaluation** sets". The evaluation set here refers to the public eval set of ARC-AGI-1! This sounds like training on test!

    On github, the HRM authors clarified that they only trained on the *examples* of the public eval set, not the *questions* of the public eval set. This "contraversy" set AI twitter on fire [[1](https://x.com/Dorialexander/status/1951954826545238181), [2](https://github.com/sapientinc/HRM/issues/18), [3](https://github.com/sapientinc/HRM/issues/1) [4](https://github.com/sapientinc/HRM/pull/22) [5](https://x.com/b_arbaretier/status/1951701328754852020)] ! Does this actually count as "training on test"? The HRM authors never actually trained on the the questions used to measure model performance, just the examples associated with them. However, these have very similar distributions...
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Ultimately the ARC-AGI organizers accepted HRM's submision and the concsensus on [Twitter](https://x.com/Dorialexander/status/1951954826545238181) was that it's actually completely allowed to train on the *examples* of the public eval set. But buried in a GitHub thread, HRM's lead author, Guan Wang, made an offhand comment that caught my attention:
    > "If there were genuine 100% data leakage - then model should have very close to 100% performance (perfect memorization)." -   [Guan Wang](https://github.com/sapientinc/HRM/issues/1#issuecomment-3113214308)

    That line stuck with me. If partial leakage gets you $40.3\%$ on ARC-AGI-1, what happens with *complete* leakage? If we train on the actual test questions, not just test examples, can we hit $100\%$? Can we do it with even fewer parameters than HRM (27M) or TRM (7M)? And can we do it on the more challenging ARC-AGI-2 instead of ARC-AGI-1? How far can we push this?
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    # Chaos Theory

    > "Chaos is what killed the dinosaurs, darling." - J.D. in Heathers
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    My goal was simple: create the tiniest possible model that achieves perfect performance on ARC-AGI-2 by blatantly training on the public eval set, both the examples and questions. We would deviate from HRM's acceptable approach (training on just the examples of the public eval set) and enter the morally dubious territory of training on the examples *and questions* of the public eval set.

    Now, the obvious approach would be to build a dictionary - just map each input directly to its corresponding output. But that's boring and lookup tables aren't nice mathematical functions. They're discrete, discontinuous, and definitely not differentiable. We need something else, something more elegant and interesting. To do that, we are going to take a brief detour into the world of chaos theory.

    > Note: As far as I know, Steven Piantadosi pioneered this technique in [One parameter is always enough](https://colala.berkeley.edu/papers/piantadosi2018one.pdf). Yet I first heard of it through Laurent Boué's paper [Real numbers, data science and chaos: How to fit any dataset with a single parameter](https://arxiv.org/abs/1904.12320). This paper is really a gem due its sheer creativity.

    In chaos theory, the dyadic map $\mathcal{D}$ is a simple one-dimensional chaotic system defined as

    $$
    \begin{align}
    \mathcal{D}(a)
    &=
    (2a) \bmod 1
    &
    \mathcal{D}: [0, 1] \to [0, 1].
    \tag{2}
    \end{align}
    $$

    It takes in any number between 0 and 1, doubles it, and throws away the whole number part, leaving just the fraction. That's it.
    """
    )
    return


@app.function
def D(a): return (2 * a) % 1


@app.cell
def _(np, plt):
    def _():
        a_values = np.linspace(0, 1, 100)
        fig, ax = plt.subplots()
        ax.scatter(a_values, D(a_values), label="Dyadic", s=2)
        ax.set_xlabel(r"$a$")
        ax.set_ylabel(r"$\mathcal{D}(a)$")
        ax.set_title("Dyadic Map")
        ax.legend()
        # plt.show()
        return fig

    _()
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    In chaos theory, we often study the orbit or trajectory of a chaotic system, the sequence generated by applying the chaotic map to itself over and over again. Starting with some number $a$, we apply our map to get $\mathcal{D}(a)$, and again to get $\mathcal{D}(\mathcal{D}(a))$, and so on and so forth. Let

    $$
    \begin{align*}
    \mathcal{D}^k(a)
    & :=
    \underbrace{(D \circ ... \circ D)}_{k}(a) = (2^k a) \mod 1
    \tag{3}
    \end{align*}
    $$

    mean we apply the dyadic map $k$ times to $a$. What does the orbit $(a, \mathcal{D}^1(a), \mathcal{D}^2(a), \mathcal{D}^3(a), \mathcal{D}^4(a), \mathcal{D}^5(a))$ look like?
    """
    )
    return


@app.function
def dyadic_orbit(a_L, k):
    orbits = [a_L]
    for _ in range(k):
        orbits.append(D(orbits[-1]))
    return orbits


@app.cell
def _():
    dyadic_orbit1 = dyadic_orbit(0.5, 5)
    return


@app.cell
def _():
    dyadic_orbit2 = dyadic_orbit(1/3, 5)
    return


@app.cell
def _():
    dyadic_orbit3 = dyadic_orbit(0.431, 5)
    return (dyadic_orbit3,)


@app.cell
def _(decimal_to_binary, dyadic_orbit3):
    dyadic_orbit3_binary = [decimal_to_binary(x, len(dyadic_orbit3)-i)[0] for i, x in enumerate(dyadic_orbit3)]
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    * If $a = 0.5$, the orbit is $(0.5, 0.0, 0.0, 0.0, 0.0, 0.0)$.
    * If $a = 1/3$, the orbit is $(0.333, 0.667, 0.333, 0.667, 0.333, 0.667,)$
    * If $a = 0.431$, the orbit is $(0.431, 0.862, 0.724, 0.448, 0.897, 0.792)$

    One orbit seems to end in all zeros, another bounces back and forth between $0.333$ and $0.667$, and a third seems to have no pattern at all. On the surface, these orbits do not have much in common. But if we take a closer look, they all share the same underlying pattern.

    Let's revisit the third orbit for $a = 0.431$ but this time we will analyze its binary representation:

    | Iterations | Decimal | Binary | Observation |
    |------------|------------------------|----------------------|-------------|
    | 0 | $a = 0.431$ | $\text{bin}(a) = 0.011011...$ | Original number |
    | 1 | $D^1(a) = 0.862$ | $\text{bin}(D^1(a)) = 0.11011...$ | First bit of $a$ $(0)$ removed |
    | 2 | $D^2(a) = 0.724$ | $\text{bin}(D^2(a)) = 0.1011...$ | First two bits of $a$ $(01)$ removed |
    | 3 | $D^3(a) = 0.448$ | $\text{bin}(D^3(a)) = 0.011...$ | First three bits of $a$ $(011)$ removed |
    | 4 | $D^4(a) = 0.897$ | $\text{bin}(D^4(a)) = 0.11...$ | First four bits of $a$ $(0110)$ removed |
    | 5 | $D^5(a) = 0.792$ | $\text{bin}(D^5(a)) = 0.1...$ | First four bits of $a$ $(01101)$ removed |

    Looking at the Binary column, we see that **every time we apply the dyadic map, the most significant bit is removed**! We start off with $0.011011$, and then applying $\mathcal{D}$ once removes the leftmost $0$ to get $0.11011$, and applying $\mathcal{D}$ another time removes the leftmost $1$ to get $0.1011$. Although the orbit appears irregular in its decimal representation, a clear pattern emerges from the binary representation.

    What is going on here?

    Each time we call $D(a) = (2a) \mod 1$, we double and truncate $a$. The doubling shifts every binary digit one place to the left and the truncation throws away whatever digit lands in the one's place. In other words, each application of $\mathcal{D}$ peels off the first binary digit and throws it away. **If we apply the dyadic map $k$ times, we remove the first $k$ bits of $a$.**

    We can see this process also holds for our other orbits:

    * If $a = 0.5$, we get the orbit $(0.5, 0.0, 0.0, 0.0, 0.0, 0.0)$ because $\text{bin}(a) = 0.100000...$ and after discarding the first bit, which is a $1$, we are left with all zeros.
    * If $a = 1/3$, we get the orbit $(0.333, 0.667, 0.333, 0.667, 0.333, 0.667)$ because $\text{bin}(a) = 0.010101...$, an infinite sequence of bits alternating between $1$ and $0$. When the bits start with a 0, we get $0.010101...$ which is $1/3 = 0.333$ in decimal. And when the bits start with a $1$, $0.10101...$, we get $2/3 = 0.667$ in decimal.

    Remarkably, these orbits are all governed by the same rule: remove one bit of information every time the dyadic map is applied. As each application of $\mathcal{D}$ removes another bit, this moves us deeper into the less significant digits of our original number -- the digits that are most sensitive to noise and measurement errors. A tiny change in $a$ due to noise, affecting the least significant bits of $a$, would eventually bubble up to the surface and completely change the orbit. That's why this system is so chaotic -- it is incredibly sensitive to even the smallest changes in the initial value $a$.

    (Note: we always compute the dyadic map on *decimal* numbers, not binary numbers; however, conceptually it is helpful to think about the binary representations of the orbit.)
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    # The Dyadic Map As An ML Model
    > "When I grow up, I'm going to be a real ~~boy~~ ML Model" - the Dyadic Map if it were staring in Pinacoi
    """
    )
    return


@app.cell
def _():
    p_ = 6
    return (p_,)


@app.cell
def _(decimal_to_binary, p_):
    # initalize alpha
    b1 = decimal_to_binary(0.5, p_)[0]
    b2 = decimal_to_binary(1/3, p_)[0]
    b3 = decimal_to_binary(0.43085467085, p_)[0]
    b = ''.join([b1, b2, b3])
    print(f'{b1=}\n{b2=}\n{b3=}\n{b=}')
    return (b,)


@app.cell
def _(b, binary_to_decimal, decimal_to_binary, p_):
    alpha0_dec = binary_to_decimal(b)
    alpha0_bin = decimal_to_binary(alpha0_dec, 18)[0]
    b0_pred_bin = decimal_to_binary(alpha0_dec, p_)[0]
    x0_pred_dec = binary_to_decimal(b0_pred_bin)
    print(f'{alpha0_dec=}\n{alpha0_bin=}\nbin(alpha)[0:6]={b0_pred_bin}\nx^_0=dec(bin(alpha)[0:6])={x0_pred_dec}')
    return (alpha0_dec,)


@app.cell
def _(alpha0_dec, binary_to_decimal, decimal_to_binary, p_):
    alpha1_dec = dyadic_orbit(alpha0_dec, p_)[-1]
    alpha1_bin = decimal_to_binary(alpha1_dec, 18-p_)[0]
    b1_pred_bin = decimal_to_binary(alpha1_dec, p_)[0]
    x1_pred_dec = binary_to_decimal(b1_pred_bin)
    print(f'{alpha1_dec=}\n{alpha1_bin=}\nbin(D^6(alpha))[0:6]={b1_pred_bin}\nx^_1=dec(bin(D^6(alpha))[0:6])={x1_pred_dec}')
    return (alpha1_dec,)


@app.cell
def _(alpha1_dec, binary_to_decimal, decimal_to_binary, p_):
    alpha2_dec = dyadic_orbit(alpha1_dec, p_)[-1]
    alpha2_bin = decimal_to_binary(alpha2_dec, 18-2*p_)[0]
    b2_pred_bin = decimal_to_binary(alpha2_dec, p_)[0]
    x2_pred_dec = binary_to_decimal(b2_pred_bin)
    print(f'{alpha2_dec=}\n{alpha2_bin=}\nbin(D^12(alpha))[0:6]={b2_pred_bin}\nx^_2=dec(bin(D^12(alpha))[0:6])={x2_pred_dec}')
    return


@app.cell
def _(mo):
    mo.md(r"""We've discovered something remarkable: each application of $\mathcal{D}$ peels away exactly one bit. But here's the question: if the dyadic map can systematically extract a number's bits, is it possible to put information in those bits in the first place? **What if we encode our dataset into a number's bits (`model.fit`) and then use the dyadic map as the core of a predictive model, extracting out the answer bit by bit (`model.predict`)?** In other words, can we turn the dyadic map into an ML model?""")
    return


@app.cell
def _(mo):
    mo.md(r"""## A Worked Example""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Suppose our dataset contains the three numbers we saw before

    $$
    \mathcal{X}
    =
    \{x_0, x_1, x_2\}
    =
    \{0.5, 1/3,  0.431\}.
    $$

    Let's convert each number to binary and look at the first $p=6$ binary digits for simplicity:

    $$
    \mathcal{B}
    =
    \{b_0, b_1, b_2\}
    =
    \{ \text{bin}_6(x_0), \text{bin}_6(x_1), \text{bin}_6(x_2)\}
    =
    \{0.100000, 0.010101, 0.011011\}
    $$

    where the function $b_i = \text{bin}_p(x_i)$ converts decimal numbers to $p$-bit binary numbers. Now comes the clever part: we glue these binary strings together, end to end:

    $$
    b
    =
    0.
    \underbrace{100000}_{b_0}
    \underbrace{010101}_{b_1}
    \underbrace{011011}_{b_2}
    $$

    and convert this binary string back to decimal

    $$
    \alpha = \text{dec}(b) = 0.50522994995117188
    $$

    The number $\alpha$ is carefully engineered so that it is a decimal number whose bits contain our entire dataset's binary representation. That's right: **we've just compressed our entire dataset into a single decimal number!** We only have one parameter, not billions here! This is a very simple, stupid version of $\alpha = \text{model.fit}(\mathcal{X})$.

    But here's the question: given $\alpha$, how do we get our data $\mathcal{X}$ back out? How do we do $\tilde{x}_i = \text{model.predict}(\alpha)$? This is where the dyadic map becomes our extraction tool.

    *Step 1.* Trivially, we know the first 6 bits of $\alpha$ contains $b_0$.

    $$
    \begin{align*}
        \alpha
        &=
        0.50522994995117188
        \\
        \text{bin}(\alpha)
        &=
        0.\underbrace{100000}_{b_0}\underbrace{010101}_{b_1}\underbrace{011011}_{b_2}
        =
        0.100000010101011011
    \end{align*}
    $$

    So we'll just record the first $6$ bits of $\alpha$ to get $b_0$.

    $$
    \begin{align*}
        b_0
        &=
        \text{bin}(\alpha)_{0:6}
        =
        100000
    \end{align*}
    $$

    If we convert this number $b_0$ back to decimal, we'll recover our original data, up to the first $6$ digits of precision.

    $$
    \begin{align*}
        \tilde{x}_0
        &=
        \text{dec} ( b_0 )
        =
        0.500000
    \end{align*}
    $$

    Now from $\alpha$ we've extracted the prediction $\tilde{x}_0 = 0.500000$ which matches exactly the $0$th sample of our dataset $x_0 = 0.5$.

    *Step 2.* To predict the next number, $\tilde{x}_1$, remember that each application of $\mathcal{D}$ strips away the leftmost binary digit. So

    $$
    \begin{align*}
        D^6(\alpha)
        &=
        0.334716796875
    \end{align*}
    $$

    strips away the first $6$ bits of $\alpha$, which just removes $b_0$, and leaves us with $b_1, b_2$

    $$
    \begin{align*}
        \text{bin}(D^6(\alpha))
        &=
        0.\underbrace{\hspace{1cm}}_{b_0}\underbrace{010101}_{b_1}\underbrace{011011}_{b_2}
        =
        0.010101011011
    \end{align*}
    $$

    Like before, we'll then record the first $6$ bits of $D^6(\alpha)$ to get $b_1$

    $$
    \begin{align*}
        b_1
        &=
        \text{bin}(D^6(\alpha))_{0:6}
        =
        010101
    \end{align*}
    $$

    and convert $b_1$ back to decimal to get $\tilde{x}_1$

    $$
    \begin{align*}
        \tilde{x}_1
        &=
        \text{dec} (b_1)
        =
        0.328125
    \end{align*}
    $$

    Here our prediction $\tilde{x}_1 = 0.328125$ is slightly off from the true value $x_1 = 1/3$ due to the limits of $6$-bit precision. If we'd have more digits of precision and increase $p$, $\tilde{x}_1$ would be closer to $x_1$.

    *Step 3.* To get the next number, $b_2$, apply $\mathcal{D}$ another 6 times to remove a total of $12$ bits from $\alpha$, 

    $$
    \begin{align*}
        D^{12}(\alpha)
        &=
        0.421875
    \end{align*}
    $$

    which strips off $b_0, b_1$ and leaves us with just $b_2$

    $$
    \begin{align*}
        \text{bin}(D^{12}(\alpha))
        &=
        0.\underbrace{\hspace{1cm}}_{b_0}\underbrace{\hspace{1cm}}_{b_1}\underbrace{011011}_{b_2}
        =
        0.011011
    \end{align*}
    $$

    Like before, we'll then record the first $6$ bits of $D^{12}(\alpha)$ to get $b_2$

    $$
    \begin{align*}
        b_2
        &=
        \text{bin}(D^{12}(\alpha))_{0:6}
        =
        011011
    \end{align*}
    $$

    and convert $b_2$ back to decimal to get $\tilde{x}_2$

    $$
    \begin{align*}
        \tilde{x}_2
        &=
        \text{dec} (b_2)
        =
        0.421875
    \end{align*}
    $$

    Notice again that our prediction $\tilde{x}_2 = 0.421875$ is slightly off from the true value $x_2 = 0.431$ due to the limitations of $6$-bit precision. 

    Let

    $$
    \begin{align*}
        \tilde{\mathcal{X}}
        &=
        \big \{\tilde{x}_0, \tilde{x}_1, \tilde{x}_2 \big\}
        =
        \big \{ 0.500000,  0.328125, 0.421875 \big \}
    \end{align*}
    $$

    be the predictions made by our strange dyadic model. If everything is correct, our predicted dataset $\tilde{\mathcal{X}}$ should perfectly equal our original dataset $\mathcal{X}$ up to the first $p$ bits.


    These 3 steps are summerized in the table below.

    | Iteration $i$ |$ip$ bits removed | $\mathcal{D}^{ip}(\alpha)$ in decimal | $\mathcal{D}^{ip}(\alpha)$ in binary | $b_i$, the first $p$ bits of $\mathcal{D}^{ip}(\alpha)$ in binary |  $\tilde{x}_i$, the first $p$ bits of $\mathcal{D}^{ip}(\alpha)$ in decimal|
    |------------|------------------------|----------------------|-------------|-------------|-------------|
    | $0$ | $0 \cdot 6 = 0$ | $\alpha = 0.50522994995117188$ | $\text{bin}(\alpha) = 0.\underbrace{100000}_{b_0}\underbrace{010101}_{b_1}\underbrace{011011}_{b_2}$ | $b_0 = 010101$ | $\tilde{x}_0 = 0.500000$|
    | $1$ | $1 \cdot 6 = 6$ | $\mathcal{D}^6(\alpha) = 0.33471679687500000$ | $\text{bin}(D^6(\alpha)) = 0.\underbrace{\hspace{1cm}}_{b_0}\underbrace{010101}_{b_1}\underbrace{011011}_{b_2}$ | $b_1 = 010101$| $\tilde{x}_1 = 0.328125$|
    | $2$ | $2 \cdot 6 = 12$ | $\mathcal{D}^{12}(\alpha) = 0.42187500000000000$ | $\text{bin}(D^{12}(\alpha)) = 0.\underbrace{\hspace{1cm}}_{b0}\underbrace{\hspace{1cm}}_{b1}\underbrace{011011}_{b_2}$ | $b_2 = 011011$| $\tilde{x}_2 = 0.421875$|

    In decimal, we go from $\alpha = 0.50522994995117188$ to $\mathcal{D}^6(\alpha) = 0.33471679687500000$ and then to $\mathcal{D}^{12}(\alpha) = 0.42187500000000000$. Although this pattern looks completely random, we are shifitng bits with superb precision. This is anything but random.

    Think about what we've accomplished here. We just showed that you can take a dataset compress it down to a single real number, $\alpha$. Then, using nothing more than repeated doubling and truncation via $\mathcal{D}$, we can perfectly recover every data point $\tilde{\mathcal{X}}$ up to $p$ bits of precision. The chaotic dynamics of the dyadic map, which seemed like a nuisance, turns out to be the precise mechanism we need to systematically access the desired information.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## The Algorithm""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    The algorithm itself is deceptively simple once you see the pattern:

    > **Encoding Algorithm:**
    > Given a dataset $\mathcal{X} = \{x_0, ..., x_{n-1}\}$ where $x_i \in [0, 1]$, encode the dataset into $\alpha$:
    >
    > 1. Convert each number to binary with $p$ bits of precision $b_i = \text{bin}_p(x_i)$ for $i=0, ..., n-1$
    > 2. Concatenate into a single binary string $b = b_0 \oplus  ... \oplus b_{n-1}$
    > 3. Convert to decimal $\alpha = \text{dec}(b)$


    The result is a single, decimal, scalar number $\alpha$ with $np$ bits of precision that contains our entire dataset. We can now discard $\mathcal{X}$ entirely.

    > **Decoding Algorithm:**
    > Given sample index $i \in \{0, ..., n-1\}$ and the encoded number $\alpha$, recover sample $\tilde{x_i}$:
    >
    > 1. Apply the dyadic map $\mathcal{D}$ exactly $ip$ times $\tilde{x}'_i = \mathcal{D}^{ip}(\alpha) = (2^{ip} \alpha) \mod 1$ 
    > 2. Extract the first $p$ bits of $\tilde{x}'_i$'s binary representation $b_i = \text{bin}_p(\tilde{x}'_i)$
    > 3. Covert to decimal $\tilde{x}_i = \text{dec}(b_i)$


    Mathematically, we can express these two algorithms with an encoder function $g: [0, 1]^n \to [0, 1]$ that compresses the dataset and a decoder function $f: \overbrace{[0, 1]}^{\alpha} \times \overbrace{\mathbb{Z}_+}^{p} \times \overbrace{[n]}^i \to [0, 1]$ that extracts individual data points:

    $$
    \begin{align*}
    \alpha
    &=
    g(p, \mathcal{X}) := \text{dec} \Big( \bigoplus_{x_i \in \mathcal{X}} \text{bin}_p(x_i) \Big)
    \tag{4}
    \\
    \tilde{x}_i
    &=
    f_{\alpha, p}(i) := \text{dec} \Big( \text{bin}_p \Big( \mathcal{D}^{ip}(\alpha) \Big) \Big)
    \end{align*}
    $$

    where $\oplus$ means concatenation.

    The precision parameter $p$ controls the trade-off between accuracy and storage efficiency. The larger $p$ is, the more accurately our encoding, but the more storage it takes up. Our error bound is

    $$
    |\tilde{x}_i - x_i | < \frac{1}{2^p}
    $$

    because we don't encode anything after the first $p$ bits of precision.

    What makes this profound is the realization that we're not really "learning" anything in any conventional sense. We're encoding it directly into the bits of a real number, exploiting it's infinite precision, and then using the dyadic map to navigate through that number and extract exactly what we need, when we need it.

    From this perspective, the dyadic map resembles a classical ML model where the encoder $g$ acts as `model.fit()` and the decoder $f$ acts as `model.predict()`.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    # Applying Some Makeup

    > "You don’t want to overdo it with too much makeup" - Heidi Klum
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    How do we go from the ugly, discontinuous decoder function

    $$
    f_{\alpha,p}(i) := \text{dec} \Big( \text{bin}_p \Big( \mathcal{D}^{ip}(\alpha) \Big) \Big)
    $$

    to that beautiful function I promised you at the start of the blog

    $$ f_{\alpha, p}(i)
    =
    \sin^2 \Big(
        2^{i p} \arcsin^2(\sqrt{\alpha})
    \Big)
    ?
    $$

    In this section we will "apply makeup" to the first function to get it looking a bit closer to the second function. We will keep the same core logic but make the function more ascetically pleasing. To do this, we will need another one-dimensional chaotic system, the [logistic map](https://en.wikipedia.org/wiki/Logistic_map).
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## Logistic Map""")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    The logistic-map at $r=4$ on the unit interval is defined as

    $$
    \begin{align*}
    \mathcal{L}(a_L)
    &=
    4 a_L (1 - a_L)
    &
    \mathcal{L}: [0, 1] \to [0, 1]
    \tag{6}
    \end{align*}
    $$

    which seems quite different than the familiar dyadic map

    $$
    \begin{align*}
    \mathcal{D}(a_D)
    &=
    (2 a_D) \mod 1
    &
    \mathcal{D}: [0, 1] \to [0, 1]
    \end{align*}
    $$

    One is a bit-shifting operation, the other is a smooth parabola that ecologists use to model population growth. (Note: previously $a$ was the input to the dyadic map but from now on $a_D$ will be the input to the dyadic map to differentiate it from $a_L$, the input to the logistic map.)
    """
    )
    return


@app.function
def L(a): return 4 * a * (1 - a)


@app.cell
def _(np, plt):
    def _():
        a_values = np.linspace(0, 1, 100)

        fig, ax = plt.subplots()
        ax.scatter(a_values, D(a_values), label="Dyadic", s=2)
        ax.scatter(a_values, L(a_values), label="Logistic", s=2)
        ax.set_xlabel(r"$a$")
        ax.set_ylabel(r"$\mathcal{D}(a)$ or $\mathcal{L}(a)$")
        ax.set_title("Logistic vs Dyadic Map")
        ax.legend()
        # plt.show()
        return fig


    _()
    return


@app.function
def logistic_orbit(a_L, k):
    orbits = [a_L]
    for _ in range(k):
        orbits.append(L(orbits[-1]))
    return orbits


@app.cell
def _():
    orbit_1 = logistic_orbit(0.5, 5)
    return


@app.cell
def _():
    orbit_2 = logistic_orbit(1/3, 5)
    return


@app.cell
def _():
    orbit_3 = logistic_orbit(0.431, 5)
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    What does the logistic orbit $(a_L, \mathcal{L}^1(a_L), \mathcal{L}^2(a_L), \mathcal{L}^3(a_L), \mathcal{L}^4(a_L), \mathcal{L}^5(a_L))$ look like? Similar or different to the dyadic orbit $(a_D, \mathcal{D}^1(a_D), \mathcal{D}^2(a_D), \mathcal{D}^3(a_D), \mathcal{D}^4(a_D), \mathcal{D}^5(a_D))$?

    * If $a_L = a_D = 0.5$, the logistic orbit is $(0.5, 1.0, 0.0, 0.0, 0.0, 0.0)$ while the dyadic orbit is $(0.5, 0.0, 0.0, 0.0, 0.0, 0.0)$. Although the dyadic orbit is just all zeros, the logistic orbit actually has $1.0$ as the second number in the orbit.
    * If $a_L = 1/3$, the logistic orbit is $(0.333, 0.888, 0.395, 0.956, 0.168, 0.560)$ while the dyadic orbit is $(0.333, 0.667, 0.333, 0.667, 0.333, 0.667)$. While the dyadic orbit repeats in a simple pattern, the logistic orbit is seemingly patternless.
    * If $a_L = 0.43085467085$, the logistic orbit is $(0.431, 0.981, 0.075, 0.277, 0.800, 0.639)$ while the dyadic orbit is $(0.431, 0.862, 0.724, 0.448, 0.897, 0.792)$. Both orbits here seem totally random and chaotic, but each in their own way.

    The logistic and dyadic maps create orbits that look nothing alike!

    However, [topological conjugacy](https://en.wikipedia.org/wiki/Topological_conjugacy) tells us these two maps are *actually* the same. Not similar. Not analgous. The same. They have identical orbits, the exact same chaotic trajectories, simply expressed in different coordinates. The logistic map, for all its smooth curves and elegant form, is actually doing discrete binary operations under the hood, just like the dyadic map (and vice versa). Formally, two functions are topologically conjugate if there exists a homeomorphism, fancy talk for a change of coordinates, that perfectly takes you from one map to another. The change of coordinates here is

    $$
    \begin{align*}
    a_L = \phi(a_D) &= \sin^2(2 \pi a_D)
    &
    \phi: [0, 1] -> [0, 1]
    \tag{7}
    \\
    a_D
    =
    \phi^{-1}(a_L)
    &=
    \frac{1}{2 \pi} \arcsin (\sqrt{a_L})
    &
    \phi^{-1}: [0, 1] -> [0, 1]
    \tag{8}
    \end{align*}
    $$

    We can map any $a_L$ to an $a_D$ and any $a_D$ to an $a_L$.
    """
    )
    return


@app.cell
def _(np, plt):
    def _():
        a_values = np.linspace(0, 1, 100)
        def phi(a): return np.sin(2 * np.pi * a) ** 2
        def phi_inverse(a): return np.arcsin(np.sqrt(a)) / (2.0 * np.pi)

        fig, ax = plt.subplots()
        ax.scatter(a_values, phi(a_values), label="phi", s=2, c="g")
        ax.scatter(a_values, phi_inverse(a_values), label="phi inverse", s=2, c="r")
        ax.set_xlabel("a")
        ax.set_ylabel("output")
        ax.set_title("phi and phi inverse")
        ax.legend()
        # plt.show()
        return fig

    _()
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Looking at the plot, the function $\phi$ has a period of 1, meaning it repeats the same values every time $a_D$ increases by $1$. This periodicity is crucial because it allows us to drop the modulo operation from the dyadic map $\mathcal{D}(a_D) = (2 a_D) \mod 1$ when transforming from the dyadic space to the logistic space. Formally,

    $$
    \begin{align*}
    \phi(a_D \mod 1) = \phi(a_D)
    \tag{9}
    \end{align*}
    $$

    which will be important later on. To go back and forth between the dyadic and logistic maps, we apply $\phi$ to the output $\mathcal{D}$ and get $\mathcal{L}$; we can also apply $\phi^{-1}$ to the input $a_L$ to get $\mathcal{D}$. Mathemtically,

    $$
    \begin{align*}
    \mathcal{L}(a_L)
    &=
    \phi(\mathcal{D}(a_D))
    \\
    \mathcal{D}(a_D)
    &=
    \mathcal{L}(\phi^{-1}(a_L))
    \end{align*}
    $$

    Here $\phi$ takes us to the logistic space and $\phi^{-1}$ takes us back to the dyadic space. This is astonishing! $\phi$ is just a sin wave squared and with a period of one. It's inverse, $\phi^{-1}$ is even weirder looking with an $\arcsin$. But somehow these functions allow us to bridge the two maps $\mathcal{D}$ and $\mathcal{L}$!

    Moreover, $\phi$ and $\phi^{-1}$ perfectly relate *every* single point in the infinite orbits of $\mathcal{D}$ and $\mathcal{L}$:

    $$
    (a_D, \mathcal{D}^1(a_D), \mathcal{D}^2(a_D), ...) = (a_L, \mathcal{L}^1(\phi^{-1}((a_L)), \mathcal{L}^2(\phi^{-1}((a_L)), ...)
    $$

    or it can be expressed as

    $$
    (a_L, \mathcal{L}^1(a_L), \mathcal{L}^2(a_L), ...) = (a_D, \phi(\mathcal{D}^1(a_D)), \phi(\mathcal{D}^2(a_D)), ...)
    $$

    depending on if we want to be natively using the coordinate system of $\mathcal{D}$ or $\mathcal{L}$. What appears as chaos in one coordinate system manifests as the exact same chaos in the other, *no matter how many iterations we apply*. Mathematically, this suggests something stronger:

    $$
    \begin{align*}
    \mathcal{L}^k(a_L)
    &=
    \phi(\mathcal{D}^k(a_D))
    \tag{10}
    \\
    \mathcal{D}^k(a_D)
    &=
    \mathcal{L}^k(\phi^{-1}(a_L))
    \tag{11}
    \end{align*}
    $$

    Think of these two orbits existing in parallel universes with $\phi$ and $\phi^{-1}$ acting as the bridges between $\mathcal{D}$ and $\mathcal{L}$.
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    topological_conjugacy_image = mo.image(
        fix_marimo_path("public/images/topological_conjugacy.png"),
        width=400,
        caption="Topological conjugacy between the dyadic and logistic map.",
        style={"display": "block", "margin": "0 auto"}
    )
    return (topological_conjugacy_image,)


@app.cell
def _(mo, topological_conjugacy_image):
    mo.md(f"""{topological_conjugacy_image}""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    We can now revist the dyadic and logistic orbits when $a_D = a_L = 0.431$.

    * When $a_D = a_L = 0.431$, we know the **dyadic orbit** is $(0.431, 0.862, 0.724, 0.448, 0.897, 0.792)$. If we apply $\phi$ to every output element $\phi(\mathcal{D}^k(a_D))$, we get $(0.431, 0.981, 0.075, 0.277, 0.800, 0.639)$. This is exactly the logistic orbit  we saw in eqn. (10)!
    * When $a_D = a_L = 0.431$,, we know the **logistic orbit** $(0.431, 0.981, 0.075, 0.277, 0.800, 0.639)$. If we apply $\phi^{-1}$
    to every input element before the logistic map $\mathcal{L}(\phi^{-1}(a_L)))$ we get the dyadic orbit $(0.431, 0.862, 0.724, 0.448, 0.897, 0.792)$.

    We see that although both these orbits look completly unrelated, these two orbits are perfectly connected to one another through $\phi$ and $\phi^{-1}$.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## A New Algorithm""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    **Can we use the topological conjugacy of $\mathcal{D}$ and $\mathcal{L}$ as makeup?**

    While $\mathcal{D}$ is ugly and discontinuous, $\mathcal{L}$ is smooth and differentiable. We can use the logistic map as "makeup" to hide the crude dyadic operations. We want our decoder to use $\mathcal{L}$ instead of $\mathcal{D}$. But for the encoder to glue together the bits of our dataset, we needs to be in the dyadic space so our clever bit manipulations will still work out. Here's the strategy:

    1. Encoder: Work in dyadic space where bit manipulation works (use $\phi$) but output parameter in logistic space (use $\phi^{-1}$)
    2. Decoder: Work entirely in smooth logistic space using the conjugacy relationship

    This gives us two new beautiful encoder/decoder algorithms where the main changes are bolded:

    > **Encoding Algorithm:**
    > Given a dataset $\mathcal{X} = \{x_0, ..., x_n\}$ where $x_i \in [0, 1]$, encode the dataset into $a_L$:
    >
    > 1. ***Transform data to dyadic coordinates: $z_i = \phi^{-1}(x_i) = \frac{1}{2 \pi} \arcsin⁡( x_i )$ for $i=1, ..., n$***
    > 2. Convert each transformed number to binary with $p$ bits of precision: $b_i = \text{bin}_p(z_i)$ for $i=1, ..., n$
    > 3. Concatenate into a single binary string $b = b_0 \oplus  ... \oplus b_n$
    > 4. Convert to decimal $a_D = \text{dec}(b)$
    > 5. ***Transform to logistic space: $\alpha = a_L = \phi(a_D) = \sin^2(2 \pi a_D)$***

    The result is a single, decimal, scalar number $\alpha$ with $np$ bits of precision that contains our entire dataset. We can now discard $\mathcal{X}$ entirely.

    > **Decoding Algorithm:**
    > Given sample index $i$ and the encoded number $\alpha$, recover sample $\tilde{x_i}$:
    >
    > 1. ***Apply the logistic map $\mathcal{L}$ exactly $ip$ times $\tilde{x}'_i = \mathcal{L}^{ip}(\alpha) = \sin^2 \Big(2^{i p} \arcsin^2(\sqrt{\alpha}) \Big)$***
    > 2. Extract the first $p$ bits of $\tilde{x}'_i$'s binary representation $b_i = \text{bin}_p(\tilde{x}'_i)$
    > 3. Covert to decimal $\tilde{x}_i = \text{dec}(b_i)$
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Mathematically, we can express this with a new and improved encoder $g$ and decoder $f$:

    $$
    \begin{align*}
    \alpha
    &=
    g(p, \mathcal{x}) := \phi \bigg( \text{dec} \Big( \bigoplus_{x \in \mathcal{X}} \text{bin}_p(\phi^{-1}(x)) \Big) \bigg)
    \\
    \tilde{x}_i
    &=
    f_{\alpha,p}(i)
    :=
    \text{dec} \Big( \text{bin}_p \Big( \mathcal{L}^{ip}(\alpha) \Big) \Big)
    =
    \text{dec} \Big( \text{bin}_p \Big( \sin^2 \Big(2^{ip} \arcsin(\sqrt{\alpha}) \Big) \Big) \Big)
    \end{align*}
    $$

    where $\oplus$ means concatenation. The decoder here is tantalizingly close to the function I promised at the start:

    $$ f_{\alpha, p}(i)
    =
    \sin^2 \Big(
        2^{x p} \arcsin^2(\sqrt{\alpha})
    \Big)
    $$

    but is still wrapped with those pesky $\text{dec}$ and $\text{bin}_p$ operations. However, something profound has happened here. We've taken the crude, discontinuous dyadic map and transformed it into something smooth and differentiable. The logistic map doesn't *look* like it's doing binary operations, but underneath the elegant trigonometry, it's performing exactly the same bit manipulations as its topological coungant, the dyadic map. Indeed, the makeup looks pretty great!

    However, nothing is free. The cost of using the logistic map instead of the dyadic map is that our error is now $2 \pi$ times larger, $|\tilde{x}_i - x_i | < \frac{\pi}{2^{p-1}}$. (We get this $2 \pi$ factor by noting that the derivative of $\phi$ is bounded by $2 \pi$ and applying the mean-value theorem. For more details, see section 2.5 of "Real numbers, data science and chaos: How to fit any dataset with a single parameter".)
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    /// details | How did we get $\mathcal{L}^{ip}(\alpha) = \sin^2 \Big(2^{i p} \arcsin^2(\sqrt{\alpha}) \Big)$?

    We just need to perform some simple algebraic manipulation with our equations:

    $$
    \begin{align*}
    \mathcal{L}^k(\alpha)
    &=
    \mathcal{L}^k(a_L)
    &
    \text{by $\alpha = a_L$}
    \\
    &=
    \phi(\mathcal{D}^k(a_D))
    &
    \text{by $(10)$}
    \\
    &=
    \phi((2^k a_D) \mod 1)
    &
    \text{by $(3)$}
    \\
    &=
    \phi(2^k a_D)
    &
    \text{by $(9)$}
    \\
    &=
    \sin^2(2 \pi \cdot (2^k a_D))
    &
    \text{by $(7)$}
    \\
    &=
    \sin^2 \bigg(2 \pi 2^k \Big( \frac{1}{2 \pi} \arcsin(\sqrt{a_L}) \Big) \bigg)
    &
    \text{by $(8)$}
    \\
    &=
    \sin^2 \Big(2^k \arcsin(\sqrt{a_L}) \Big)
    &
    \text{by simplification}
    \\
    &=
    \sin^2 \Big(2^k \arcsin(\sqrt{\alpha}) \Big)
    &
    \text{by $\alpha = a_L$}
    \end{align*}
    $$
    ///
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""# Code Implementation""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Now comes the moment of truth. We've built up all this beautiful math about chaos theory and topological conjugacy, but can we actually code it up?

    If you've been paying attention, there is one crucial implementation detail we have to worry about. If our dataset $\mathcal{X}$ has $n$ samples, each encoded with $p$ bits, $\alpha$ will contain $np$ bits. For ARC-AGI-2 with hundreds of tasks and high precision, this could be millions of bits. Standard computers can only handle numbers with 32 or 64 bits. How do we even store $\alpha$, much less solve ARC-AGI-2 with it? 

    The answer is simple: we can use an arbitrary precision arithmetic library like [mpmath]([https://github.com/aleaxit/gmpy](https://github.com/mpmath/mpmath)) that can represent numbers with as many bits as we want. Instead of a regular Python float, we represent $\alpha$ as a mpmath float with $np$ bits of precision. We then run the decoder with mpmath operations and convert the final result back to a regular Python float. Note: operations with arbitrary precision arithmetic libraries like mpmath tend to be *significantly* slower than regular floating point operations.

    But mpmath gives us another gift: it actually removes the pesky $\text{dec}(\text{bin}_p(\cdot))$ operations from our decoder

    $$ f_{\alpha, p}(i)
    =
    \text{dec} \Big( \text{bin}_p \Big( \mathcal{L}^{ip}(\alpha) \Big) \Big).
    $$

    In our implementation, we use $\text{dec}(\text{bin}_p(\cdot))$ to truncate $\mathcal{L}^{ip}(\alpha)$ to exactly $p$ bits and then we convert $f_{\alpha, p}(i)$ from a $p$-bit mpmath number to a Python float32. During this conversion, Python copies the first $p$ bits of $f_{\alpha, p}(i)$  and then fills the remaining bits of the Python float32 (bits $p+1$ through $32$) with random meaningless junk bits (assuming $p<=32$). Since our model only guarantees accuracy for the first $p$ bits, these random bits don't matter.

    However, converting to binary and back is wildly expensive, especially when $\alpha$ contains millions of bits. Upon taking a closer look, we can, in fact, actually skip the entire $\text{dec}(\text{bin}_p(\cdot))$ step and convert $\mathcal{L}^{ip}(\alpha)$ directly to a Python float32. The first $p$ bits of $\mathcal{L}^{ip}(\alpha)$ still get copied correctly and bits $p+1$ through $32$ get filled with the higher-order bits of $\mathcal{L}^{ip}(\alpha)$ instead of random Python bits. Since our prediction only uses the first $p$ bits, these extra bits are irrelevant whether they come from Python or straight from our decoder $\mathcal{L}^{ip}(\alpha)$. Now we can get the correct answer without the expensive $\text{dec}(\text{bin}_p(\cdot))$ operation since the bits $p+1$ through $32$ are disregarded and can come from anywhere. Removing $\text{dec}(\text{bin}_p(\cdot))$, our decoder simplifies to exactly what we promised at the start:

    $$ f_{\alpha, p}(i)
    =
    \mathcal{L}^{ip}(\alpha)
    =
    \sin^2 \Big(
        2^{x p} \arcsin^2(\sqrt{\alpha})
    \Big)
    $$

    This is amazing! Usually translating math into code turns beautiful theory into ugly, complicated messes. But surprisingly, leveraging mpmath has the opposite effect and actually makes our decoder even simpler. Now let's get to the code!
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## Building Blocks""")
    return


@app.cell
def _(mo):
    mo.md(r"""First, we need to import our arbitrary-precision math library, mpmath.""")
    return


@app.cell
def _(mo):
    from mpmath import mp, asin as Arcsin, sqrt as Sqrt, sin as Sin, pi as Pi
    mo.show_code()
    return Arcsin, Pi, Sin, Sqrt, mp


@app.cell
def _(mo):
    mo.md(r"""We need some functions to convert from binary to decimal and back. We cannot simply use python's `bin` function because it only converts integers to binary and we have floats in $[0, 1]$.""")
    return


@app.cell
def _(mo, np):
    def dyadic_map(X:np.ndarray): return (2 * X) % 1
    mo.show_code()
    return (dyadic_map,)


@app.cell
def _(dyadic_map, mo, np):
    def decimal_to_binary(x_decimal:np.ndarray|float|int|list|tuple, precision:int):
        # converts a 1D sequence from decimal to binary, assume all values in [0, 1]
        if isinstance(x_decimal, (float, int)): x_decimal = np.array([x_decimal], dtype=float)
        elif isinstance(x_decimal, (list, tuple)): x_decimal = np.array(x_decimal, dtype=float)
        # elif isinstance(x_decimal, mp.mpf): x_decimal = np.array([x_decimal])
        assert 0 <= x_decimal.min() <= x_decimal.max() <= 1, f"expected x_decimal to be in [0, 1] but got [{x_decimal.min()}, {x_decimal.max()}]"
        bits = []
        for _ in range(precision):
            bits.append(np.round(x_decimal))
            # bit = np.zeros_like(x_decimal)
            # bit[x_decimal > 0.5] = 1
            # bits.append(bit)
            # print(f'{x_decimal=}')
            x_decimal = dyadic_map(x_decimal)
        # print(f'{bits=}')
        # print('np(bits)=', np.array(bits).astype(int).T.ravel())
        return ''.join(map(str, np.array(bits).astype(int).T.ravel()))
    mo.show_code()
    return (decimal_to_binary,)


@app.cell
def _(mo, mp, np):
    def binary_to_decimal(x_binary:np.ndarray):
        # converts an arbitrary-precision scalar from binary to decimal
        return mp.fsum(int(b) * mp.mpf(0.5) ** (i+1) for i, b in enumerate(x_binary))
    mo.show_code()
    return (binary_to_decimal,)


@app.cell
def _(mo):
    mo.md(r"""Next we need $\phi$ and $\phi^{-1}$ to go back and forth between the dyadic and logistic spaces.""")
    return


@app.cell
def _(Pi, Sin, mo):
    def phi(x): return Sin(2 * Pi * x) ** 2
    mo.show_code()
    return (phi,)


@app.cell
def _(mo, np):
    def phi_inverse(x): return np.arcsin(np.sqrt(x)) / (2.0 * np.pi)
    mo.show_code()
    return (phi_inverse,)


@app.cell
def _(mo):
    mo.md(
        r"""
    We can now implement the logistic encoder

    $$
    \alpha
    =
    g(p, \mathcal{x})
    =
    \phi \bigg( \text{dec} \Big( \bigoplus_{x \in \mathcal{X}} \text{bin}_p(\phi^{-1}(x)) \Big) \bigg)
    $$

    in code
    """
    )
    return


@app.cell
def _(binary_to_decimal, decimal_to_binary, mo, mp, phi, phi_inverse):
    def logistic_encoder(X, p, full_precision):
        # set the mpmath arbitrary precision before computing anything
        mp.prec = full_precision

        # 1. apply φ^(-1) for all x in X
        phi_inv_decimal_list = phi_inverse(X)

        # 2. convert to binary for all x in X
        phi_inv_binary_list = decimal_to_binary(phi_inv_decimal_list, p)

        # 3. concatenate all binary strings together into a scalar
        phi_inv_binary_scalar = ''.join(phi_inv_binary_list)
        if len(phi_inv_binary_scalar) != full_precision:
            raise ValueError(f"Expected {full_precision} bits but got {len(phi_inv_binary_scalar)} bits.")

        # 4. convert to decimal
        phi_inv_decimal_scalar = binary_to_decimal(phi_inv_binary_scalar)

        # 5. apply φ
        alpha = phi(phi_inv_decimal_scalar)
        return alpha
    mo.show_code()
    return (logistic_encoder,)


@app.cell
def _(mo):
    mo.md(
        r"""
    We compute $\alpha$ in five steps using mpmath with precision set to $np$ bits. Crucially, step 4 produces an mpmath float with the full $np$ bits of precision, which we then transform in step 5 to get our final $np$-bit parameter $\alpha$. Next, we implement the logistic decoder

    $$
    \tilde{x}_i 
    =
    f_{\alpha, p}(i)
    =
    \sin^2 \Big(
        2^{x p} \arcsin^2(\sqrt{\alpha})
    \Big)
    $$
    """
    )
    return


@app.cell
def _(Arcsin, Sin, Sqrt, mo, mp):
    def logistic_decoder(alpha, full_precision, p, i):
        # set the mpmath arbitrary precision
        mp.prec = full_precision
        return float(Sin(2 ** (i * p) * Arcsin(Sqrt(alpha))) ** 2)
    mo.show_code()
    return (logistic_decoder,)


@app.cell
def _(mo):
    mo.md(r"""Again, we set the mpmath precision to $np$ bits and implement the decoder in a single line using mpmath's arbitrary-precision functions: `Sin`, `Arcsin`, and `Sqrt`. That's it. Our entire encoder and decoder, the heart of our one-parameter model, is just a handful of lines and a bit of beautiful mathematics.""")
    return


@app.cell
def _(mo):
    mo.md(r"""## Basic Implementation""")
    return


@app.cell
def _(mo):
    mo.md(r"""Let's put our `logistic_encoder` and `logistic_decoder` functions to the test and create a one-parameter model for the first task from ARC-AGI-2's public eval set.""")
    return


@app.cell
def _(ds, plot_arcagi):
    plot_arcagi(ds, "eval", 0)
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    In this task, we have 4 example input-output pairs and a question input-output pair, seperated by the vertical line. The challenge: given the 4 examples and the question input, predict the question output by discovering the underlying pattern.

    Take a moment and see if you can spot it. It is quite hard.

    Remember, to an LLM this is just a grid of integers in $[0,9]$. We've just added colors to make it easier for humans to see the pattern. From an LLM's perspective, the outputs are:
    """
    )
    return


@app.cell
def _(ds, plot_arcagi):
    plot_arcagi(ds, "eval", 0, show_nums='outputs')
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    To make the one-parameter model work for ARC-AGI-2, we need to make three additions to our encoder, decoder functions:

    1. **Supervised learning.** ARC-AGI-2 is a supervised learning problem with input-output pairs $(X,Y)$, but our encoder can only handle unsupervised datasets $(X)$. We simply encode the outputs $Y$ instead of the inputs $X$ because the outputs $Y$ are what we actually need to memorize.
    2. **Shape handling.** Our encoder works on datasets with scalar numbers, not matrices. Simple solution: flatten the matrices into long lists during encoding and then reshape back during decoding.
    3. **Data scaling.** ARC-AGI-2 uses integers 0-9, but our encoder needs values in [0,1]. We use a standard MinMaxScaler to squeeze the data into the right range during encoding and unscale them during decoding.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""Let's take it step by step. First, we'll treat this as supervised learning approach by making `X` the question input and `y` the question output.""")
    return


@app.cell
def _(ds, mo, process_arc_agi):
    X, y = process_arc_agi(ds)
    X1, y1 = X[:1], y[:1]
    mo.show_code()
    return X, X1, y, y1


@app.cell
def _(X1, mo, y1):
    print(f'{X1.shape=}, {y1.shape=}')
    mo.show_code()
    return


@app.cell
def _(X1, mo, y1):
    with mo.redirect_stdout():
        print(f'{X1.shape=}, {y1.shape=}')
    return


@app.cell
def _(X1, mo):
    print(f'{X1[0, 0, :5]=}')
    mo.show_code()
    return


@app.cell
def _(X1, mo):
    with mo.redirect_stdout():
        print(f'{X1[0, 0, :5]=}')
    return


@app.cell
def _(mo, y1):
    print(f'{y1[0, 0, :5]=}')
    mo.show_code()
    return


@app.cell
def _(mo, y1):
    with mo.redirect_stdout():
        print(f'{y1[0, 0, :5]=}')
    return


@app.cell
def _(mo):
    mo.md(r"""Second, we transform `y` from a matrix to a list of scalars""")
    return


@app.cell
def _(mo, y1):
    y1_flat = y1.flatten()
    print(f'{y1_flat.shape=}')
    mo.show_code()
    return (y1_flat,)


@app.cell
def _(mo, y1_flat):
    with mo.redirect_stdout():
        print(f'{y1_flat.shape=}')
    return


@app.cell
def _(mo):
    mo.md(r"""The question output `y` starts out as a `30x30` matrix but flattens to 900 scalar elements. Crucially, this means to encode a single ARC-AGI-2 task, the one-parameter model must encode 900 individual scalar elements into $\alpha$. Since each element requires $p$ bits of precision, a single task demands $900p$ bits, not just `p` bits. This cost adds up quickly. To encode all 400 tasks in ARC-AGI-2's eval set into one $\alpha$ requires $400 \cdot 900p=360,000p$ bits. It is quite easy to see why our one-parameter model may require an $\alpha$ with millions of bits. For now, we'll focus on a single task, which only requires $900p$ bits.""")
    return


@app.cell
def _(mo):
    mo.md(r"""Third, we transform ARC-AGI-2 inputs from $[0, 9]$ to $[0, 1]$ with the MinMaxScaler""")
    return


@app.cell
def _(mo, np):
    class MinMaxScaler:
        def __init__(self, feature_range=(1e-10, 1-1e-10), epsilon=1e-10):
            self.min = self.max = self.range = None
            self.feature_range, self.epsilon = feature_range, epsilon
        def fit(self, X):
            self.min, self.max = X.min(axis=0), X.max(axis=0)
            self.range = np.maximum(self.max - self.min, self.epsilon)  # Prevent div by zero
            return self
        def transform(self, X):
            X_scaled = (X - self.min) / self.range
            return np.clip(X_scaled, *self.feature_range)  # Keep away from exact boundaries
        def fit_transform(self, X):
            return self.fit(X).transform(X)
        def inverse_transform(self, X):
            X_clipped = np.clip(X, *self.feature_range)
            return X_clipped * self.range + self.min
    mo.show_code()
    return (MinMaxScaler,)


@app.cell
def _(MinMaxScaler, mo, y1_flat):
    scaler = MinMaxScaler()
    y1_scaled = scaler.fit_transform(y1_flat)
    mo.show_code()
    return scaler, y1_scaled


@app.cell
def _(mo, scaler):
    print(f'{scaler.range=}')
    mo.show_code()
    return


@app.cell
def _(mo, scaler):
    with mo.redirect_stdout():
        print(f'{scaler.range=}')
    return


@app.cell
def _(mo, y1_scaled):
    print(f'{y1_scaled[:5]=}')
    mo.show_code()
    return


@app.cell
def _(mo, y1_scaled):
    with mo.redirect_stdout():
        print(f'{y1_scaled[:5]=}')
    return


@app.cell
def _(mo):
    mo.md(r"""Every entry of `y` is in the proper range, $[0, 1]$. Remember, we flatten and scale `y` (question output) and not `X` (question input) because we want to encode the question output into $\alpha$.""")
    return


@app.cell
def _(mo):
    mo.md(r"""We are ready to run our encoder and learn an $\alpha$ that captures all 900 elements in the first ARC-AGI-2 eval task. This is our `model.fit()`. Remember, this is "training on test" as this task comes from the eval set, not the train set.""")
    return


@app.cell
def _(logistic_encoder, mo, y1_scaled):
    p = 7 # bits of precision for a single sample
    full_precision = len(y1_scaled) * p # bits of precision for alpha / all samples in the dataset
    alpha = logistic_encoder(y1_scaled, p, full_precision)
    mo.show_code()
    return alpha, full_precision, p


@app.cell
def _(full_precision, mo):
    print(f'{full_precision=}')
    mo.show_code()
    return


@app.cell
def _(full_precision, mo):
    with mo.redirect_stdout():
        print(f'{full_precision=}')
    return


@app.cell
def _(alpha, mo):
    print(f'{len(str(alpha))=}')
    mo.show_code()
    return


@app.cell
def _(alpha, mo):
    with mo.redirect_stdout():
        print(f'{len(str(alpha))=}')
    return


@app.cell
def _(mo):
    mo.md(r"""We encode each sample with $p=7$ bits of precision. Alpha is $1897$ decimal digits long and $900 \cdot 7 = 6300$ bits long. Feel free to scroll:""")
    return


@app.cell
def _(alpha, mo):
    # todo: show alpha in binary!
    mo.md(f"```py\nalpha={str(alpha)}\n\n```")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    This single $\alpha$ encodes the entire task, all 900 individual elements, perfectly. This is our one-parameter model in its full glory. All we need is this alpha and we can correctly predict the question output of this task.

    To decode and do `model.predict()`, we must run our decoder 900 times to extract all 900 invididual scalar elements from public eval task 1 of ARC-AGI-2. We use a for loop for this in `decode`.
    """
    )
    return


@app.cell
def _(alpha, full_precision, logistic_decoder, mo, np, p, tqdm, y1_scaled):
    def decode(alpha, full_precision, p, y_scaled):
        return np.array([logistic_decoder(alpha, full_precision, p, i) for i in tqdm(range(len(y_scaled)), total=len(y_scaled), desc="Decoding")])

    _y1_pred = decode(alpha, full_precision, p, y1_scaled)
    mo.show_code()
    return (decode,)


@app.cell
def _(mo):
    print(f'{_y1_pred.shape=}')
    mo.show_code()
    return


@app.cell
def _(mo):
    with mo.redirect_stdout():
        print(f'{_y1_pred.shape=}')
    return


@app.cell
def _(mo):
    mo.md(r"""Now let's undo the steps from before: reshape `_y1_pred` back into a matrix and scale it back to `[0, 9]`.""")
    return


@app.cell
def _(mo, scaler):
    y1_pred = scaler.inverse_transform(_y1_pred).reshape(1, 30, 30)
    mo.show_code()
    return (y1_pred,)


@app.cell
def _(mo, y1_pred):
    print(f'{y1_pred.shape=}')
    mo.show_code()
    return


@app.cell
def _(mo, y1_pred):
    with mo.redirect_stdout():
        print(f'{y1_pred.shape=}')
    return


app._unparsable_cell(
    r"""
    print(f'{y1_pred[0, :5, :25=}')
    mo.show_code()
    """,
    name="_"
)


@app.cell
def _(mo, y1_pred):
    with mo.redirect_stdout():
        print(f'{y1_pred[:, :5, :5]=}')
    return


@app.cell
def _(mo):
    mo.md(r"""Great, now the output of the decoder is in a usual form, `y1_pred`. Let's plot the results to see how well our one-parameter model actually did:""")
    return


@app.cell
def _(np, plot_matrix, plt):
    def plot_prediction(ds, split, i, predictions=None, precisions=None, alpha_n_digits=None, size=2.5, w=0.9, show_nums=False):
      task = ds[split][i]
      nq = len(task['question_inputs'])
      n_pred = len(predictions) if predictions is not None else 0
      mosaic = [[f'Q.{j+1}_out' for j in range(nq)] + [f'pred_{k}' for k in range(n_pred)]]
      fig, axes = plt.subplot_mosaic(mosaic, figsize=(size*(nq+n_pred), 2*size))
      plt.suptitle(f'ARC-AGI-2 {split.capitalize()} Task #{i} (id={task["id"]})', fontsize=18, fontweight='bold', y=0.98)

      for j in range(nq):
        plot_matrix(task['question_outputs'][j], axes[f'Q.{j+1}_out'], title=f"Q.{j+1} Output", status='predict', w=w, show_nums=show_nums in [True, 'outputs'] or n_pred > 0)

      if n_pred:
        if precisions is None: precisions = [None]*n_pred
        if alpha_n_digits is None: alpha_n_digits = [None]*n_pred
        for k in range(n_pred):
          pred = np.array(predictions[k])[:len(task['question_outputs'][0]), :len(task['question_outputs'][0][0])]
          title = "Q.1 Prediction"
          if precisions[k] is not None: title = f"Precision={precisions[k]}\n{title}"
          if alpha_n_digits[k] is not None: title = f"len(α)={alpha_n_digits[k]} digits\n{title}"
          plot_matrix(pred, axes[f'pred_{k}'], title=title, w=w, show_nums=True)
        fig.add_artist(plt.Line2D([nq/(nq+n_pred), nq/(nq+n_pred)], [0.05, 0.87], color='#333333', linewidth=5, transform=fig.transFigure))
        fig.text(nq/(2*(nq+n_pred)), 0.91, 'Questions', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)
        fig.text((nq+n_pred/2)/(nq+n_pred), 0.91, 'Predictions', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)
      else:
        fig.text(0.5, 0.91, 'Questions', ha='center', va='top', fontsize=13, fontweight='bold', color='#444444', transform=fig.transFigure)

      fig.patch.set_linewidth(5)
      fig.patch.set_edgecolor('#333333')
      fig.patch.set_facecolor('#eeeeee')
      plt.tight_layout(rect=[0, 0, 1, 0.94], h_pad=1.0)
      return fig
    return (plot_prediction,)


@app.cell
def _(alpha, ds, p, plot_prediction, y1_pred):
    plot_prediction(ds, "eval", 0, [y1_pred.squeeze()], [p], [len(str(alpha))])
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    The left column shows the ground truth (correct output), while the right column displays our one-parameter model's prediction. We don't display the examples or question input here. We adjust the colors to reflect the magnitude of each error: larger deviations from the ground truth produce larger differences in color.

    Look at the first row.  The correct value is 7, and we predict 6.69. The next cell should be 7, and we predict 6.72. The third cell is 9, and we predict 8.98. Across the entire grid, our predictions hover near the correct values, often off by a small decimal amount.

    What went wrong?

    These imprecisions stem from our choice of precision parameter $p$. Recall, the encoder stores each element as a $p$-bit number and discards all information after $p$ bits. This truncation introduces a quantization error of up to $\frac{\pi R}{2^{p-1}} = 0.44$ where $p=7$ is the precision and $R=9$ is the range of the MinMaxScaler. (Notice that indeed all of our errors are less than 0.44.) There is nothing wrong with our encoder or decoder; this is an unavoidable consequence of finite-precision encoding. 

    We can, however, reduce the error by increasing the precision. Let's test this with $p=14$.
    """
    )
    return


@app.cell
def _(decode, logistic_encoder, mo, scaler, y1_scaled, y_scaled):
    # encode
    y2_scaled = y1_scaled
    p2 = 14 # bits of precision for a single sample
    full_precision2 = len(y2_scaled) * p2 # bits of precision for alpha / all samples in the dataset
    alpha2 = logistic_encoder(y2_scaled, p2, full_precision2)

    # decode
    _y2_pred = decode(alpha2, full_precision2, p2, y_scaled)
    y2_pred = scaler.inverse_transform(_y2_pred).reshape(1, 30, 30)

    mo.show_code()
    return alpha2, p2


@app.cell
def _(alpha, alpha2, ds, p, p2, plot_prediction, y_pred, y_pred2):
    plot_prediction(ds, "eval", 0, [y_pred.squeeze(), y_pred2.squeeze()], [p, p2], [len(str(alpha)), len(str(alpha2))])
    return


@app.cell
def _(mo):
    mo.md(r"""When $p=14$, we get every prediction perfectly correct (up to two decimal points). However, this comes at the cost of requiring a larger $\alpha$, going from $6300$ digits to $6504$ digits or in binary, going from $900*7=63,000$ bits to $900*14=12,600$ bits. The larger $p$ is, the more accurately our encoding, but the more storage it takes up. Still, this is a pretty amazing tradeoff!""")
    return


@app.cell
def _(mo):
    mo.md(r"""## Faster Implementation""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    The decoder works great for a single task. But for every additional task, we have to decode another 900 elements. Decoding all 400 tasks in ARC-AGI-2 would take hours. We need a way to make this faster. Looking at our current decoder

    ```py
    def logistic_decoder(alpha, full_precision, p, i):
        mp.prec = full_precision
        return float(Sin(2 ** (i * p) * Arcsin(Sqrt(alpha))) ** 2)

    _y2_pred = np.array([logistic_decoder(alpha2, full_precision2, p2, i) for i in range(len(y2_scaled))])
    ```

    we can accelerate this in three ways:

    1. **Parallelization:** Because each element is decoded independently, we can decode all elements in parallel with `multiprocessing.Pool`. This speeds up the for loop over `len(y_scaled))`.
    2. **Precomputation:** Calculate `arcsin(sqrt(alpha))` once before decoding instead of recomputing it in each decoding iteration. This eliminates repeated expensive trigonmetric and square root operations.
    3. **Adaptive precision:** We currently set mpmath's precison to `full_precision = np` bits at every decoding step, even though we don't need all $np$ bits at each iteration. Instead we can use $p(i+1)+1$ bits in the $i$th decoding step, drastically reducing the number of bit-operations we do in every iteration.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    /// details | How does adaptive precision work? Why can we use $p(i+1)+1$ bits instead of $np$ bits in the $i$th decoding step?
        type: info

    Each sample is encoded in $p$ bits, so the $i$th sample occupies bits $ip$ through $ip + (p-1) = p(i+1) - 1$ of $\alpha$. The parts of $\alpha$ beyond $\alpha$ beyond $p(i+1) - 1$ bits are irrelevant in iteration $i$. 

    By setting mpmath's precision to exaclty $p(i+1) - 1$ bits in iteration $i$, we perform computation on fewer bits, increasing the precision gradually: $p$ bits in iteration $0$, $2p$ bits in iteration $1$, and so on, up to $np$ bits in the final iteration. This reduces the total arithmetic cost from $n \cdot (np)$ bit-operations to

    $$
    p(1+2+...+n) = \frac{n(n+1)}{2} p,
    $$

    which is roughly 2x fewer arithmetic operations. Theoretically this is a constant factor improvement. However, in practice this yields a dramatic speedup in mpmath. 

    A key important caveat is that this optimization only works in dyadic space where the bit structure is explicit. In logistic space, the bit positions are scrambled, making reduced precision unusable. For this reason, we apply reduced precision only after $\phi^{-1}$ transforms the value into dyadic space.

    Finally, to improve numerical stability, we set mpmath's precision to $p(i+1)+1$ bits -- two bits higher than the normal $p(i+1)-1$. These two extra bits are not for extracting additional information from $\alpha$. Instead, they act as a numerical buffer that helps preserves the accuracy of mpmath’s arithmetic. Emperically, we need this otherwise mpmath does not work properly. I'm not sure why...

    ///
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""Let's implement these three speedups in our code.""")
    return


@app.cell
def _(Sin, mo, mp):
    def logistic_decoder_fast(arcsin_sqrt_alpha, p, i):
        mp.prec = p * (i + 1) + 1
        return float(Sin(2 ** (i * p) * arcsin_sqrt_alpha) ** 2)
    mo.show_code()
    return


@app.cell
def _(mo):
    mo.md(r"""We modify `logistic_decoder_fast` to take in `arcsin_sqrt_alpha` instead of $\alpha$ and set the precision to `mp.prec = p * (i + 1) + 1` instead of `mp.prec = full_precision`.""")
    return


@app.cell
def _(mo):
    from src.one_parameter_model.model import fast_decode
    mo.show_code()
    return (fast_decode,)


@app.cell
def _(display_fxn, fast_decode, mo):
    mo.md(rf"""{display_fxn(fast_decode)}""")
    return


@app.cell
def _(mo):
    mo.md(r"""We parallelize the decoding with `multiprocessing.Pool`. Note: since `multiprocessing.Pool` [fails in notebooks](https://bobswinkels.com/posts/multiprocessing-python-windows-jupyter/) we need to define `fast_decode` in another file and import it here. This is one of the weird quirks of parallelizing operations in a notebook and why `fast_decode` is displayed differently than other functions.""")
    return


@app.cell
def _(mo):
    mo.md(r"""Let's now run a speed test and compare the fast and slow decoders on 5 ARC-AGI-2 tasks with precision $p=7$. First, we encode these 5 tasks into $\alpha$:""")
    return


@app.cell
def _(MinMaxScaler, X, logistic_encoder, mo, y):
    # encode
    def preprocess(X, y):
        y_flat = y.flatten()
        scaler = MinMaxScaler()
        y_scaled = scaler.fit_transform(y_flat)
        return y_scaled

    n_samples = 5
    y3_scaled = preprocess(X[:n_samples], y[:n_samples]) # use first 5 tasks of ARC-AGI-2
    p3 = 14 # bits of precision for a single sample
    full_precision3 = len(y3_scaled) * p3

    alpha3 = logistic_encoder(y3_scaled, p3, full_precision3)
    mo.show_code()
    return alpha3, full_precision3, p3, y3_scaled


@app.cell
def _(alpha3, mo):
    mo.md(f"""```py\nlenlen(alpha)={len(str(alpha3))}\nalpha={str(alpha3)}\n```""")
    return


@app.cell
def _(mo):
    mo.md(r"""Both the original decoder and the fast decoder use the same $\alpha$, which has 543 digits. Now let's run the decoders.""")
    return


@app.cell
def _(alpha3, decode, full_precision3, mo, p3, time, y3_scaled):
    st = time.perf_counter()
    _y3_pred = decode(alpha3, full_precision3, p3, y3_scaled)
    et = time.perf_counter()
    print(f'Decoding Took {et-st} secs')
    mo.show_code()
    return et, st


@app.cell
def _(et, mo, st):
    with mo.redirect_stdout():
        print(f'Decoding Took {et-st} secs')
    return


@app.cell
def _(alpha3, fast_decode, p3, time, y3_scaled):
    st_fast = time.perf_counter()
    _y3_pred_fast = fast_decode(alpha3, p3, y3_scaled)
    et_fast = time.perf_counter()
    print(f'Fast Decoding Took {et_fast-st_fast} secs')
    return et_fast, st_fast


@app.cell
def _(et_fast, mo, st_fast):
    with mo.redirect_stdout():
        print(f'Fast Decoding Took {et_fast-st_fast} secs')
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    The original decoder runs in 35.6 seconds and the fast decoder in 2.7 seconds. This is a 13x speedup on my Mac M1 Pro! Since we encode 5 tasks, each with 900 samples, we've decoded a total of $5 \cdot 900=4500$ individual tasks.

    Due to adaptive precision, the fast decoder may produce slightly different values after the first $p$ bits compared to the regular decoder. We verify that both decoders remain within the theoretical error tolerance of each other.
    """
    )
    return


@app.cell
def _(np, p_5):
    tol = np.pi/2**(p_5-1)
    np.testing.assert_allclose(_y3_pred, _y3_pred_fast, atol=tol)
    return


@app.cell
def _(mo):
    mo.md(r"""This is great! We now have a fast decoder implementation that can handle multiple tasks!""")
    return


@app.cell
def _(mo):
    mo.md(r"""## Final Implementation""")
    return


@app.cell
def _(mo):
    mo.md(r"""We are now ready to create the final implementation of the one-parameter model. (Again, because `multiprocessing.Pool` fails in notebooks we define `OneParameterModel` in another file and import it here.)""")
    return


@app.cell
def _(mo):
    from src.one_parameter_model.model import OneParameterModel
    mo.show_code()
    return (OneParameterModel,)


@app.cell
def _(OneParameterModel, display_fxn, mo):
    mo.md(rf"""{display_fxn(OneParameterModel)}""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    The code is quite simple and looks like a standard scikit-learn ML model:

    * `model.fit` runs the encoder. It also scales and reshapes the data.
    * `model.predict` runs the (fast) decoder. It runs the decoder in parallel and reverses the data scaling, reshaping.
    * `model.verfiy` checks that the outputted predictions are within the theoretical error bounds we derived.

    The one-parameter model is quite elegant. `OneParameterModel` itself is ~50 lines of code and the math functions it uses are probably another ~50 lines of code (`phi`, `phi_inverse`, `decimal_to_binary`, `binary_to_decimal`, `logistic_encoder`, and `logistic_decoder`). Only around 100 lines to get a perfect score on ARC-AGI-2!
    """
    )
    return


@app.cell
def _(OneParameterModel, X, y):
    p4 = 4
    model = OneParameterModel(p4)
    model.fit(X, y)
    return (model,)


@app.cell
def _(model, np):
    idx = 2
    y4_pred = model.predict(np.array([idx, idx+1]))
    return idx, y4_pred


@app.cell
def _(idx, model, np, y, y4_pred):
    model.verify(y4_pred, y[np.array([idx, idx+1])])
    return


@app.cell
def _(
    OneParameterModel,
    X,
    ds,
    functools,
    np,
    plot_arcagi,
    plt,
    process_arc_agi,
    y,
):
    @functools.cache # pylint: disable=method-cache-max-size-none
    def cached_fit(p):
        model = OneParameterModel(p)
        model.fit(X, y)
        return model

    @functools.cache # pylint: disable=method-cache-max-size-none
    def run(idx, p):
        X, y = process_arc_agi(ds)
        model = cached_fit(p)
        y_pred = model.predict(np.array([idx]))
        model.verify(y_pred, y[np.array([idx])])
        plot_arcagi(ds, "eval", idx, y_pred, show_nums=False)
        plt.show()
        print(f"p={p}\nalpha={str(model.alpha)[:10_000]}")
    return (run,)


@app.cell
def _(mo):
    precision_slider = mo.ui.slider(start=1, stop=10, step=1, show_value=True, label="Precision")
    precision_slider
    return (precision_slider,)


@app.cell
def _(mo):
    idx_slider = mo.ui.slider(start=1, stop=10, step=1, show_value=True, label="Sample")
    idx_slider
    return (idx_slider,)


@app.cell
def _(idx_slider, precision_slider, run):
    run(idx_slider.value, precision_slider.value)
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    # Conclusion

    > "With four parameters I can fit an elephant, and with five I can make him wiggle his trunk." - John von Neumann
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## Other uses for the one-parameter model""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    We've built a model that achieves 100% on ARC-AGI-2 with one parameter. Indeed, this technique is quite powerful and can be applied to tons of other datasets, achieving perfect accuracy every time.

    For instance, we can encode animal shapes with different values of $\alpha$
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    animals_image = mo.image(
        fix_marimo_path("public/images/animals.png"),
        width=800,
        caption="Encode animals with different values of alpha. Figure 1 of 'Real numbers, data science and chaos: How to fit any dataset with a single parameter'.",
        style={"display": "block", "margin": "0 auto"}
    )
    animals_image
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    We can find an $\alpha$ that perfectly predicts the fluctuations of the S&P 500 for ~6 months with
    ```py
    alpha = 0.9186525008673170697061215177743819472103574383504939864690954692792184358812098296063847317394708021665491910117472119056871470143410398692872752461892785029829514157709738923288994766865216570536672099485574178884250989741343121
    ```
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    stocks_image = mo.image(
        fix_marimo_path("public/images/s_and_p.png"),
        width=800,
        caption="Predict the S&P 500 with 100% accuracy until mid Febuary 2019. From Figure 9 of 'Real numbers, data science and chaos: How to fit any dataset with a single parameter'.",
        style={"display": "block", "margin": "0 auto"}
    )
    stocks_image
    return


@app.cell
def _(mo):
    mo.md(r"""And we can even find values of $\alpha$ that generate parts of the famous [CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10) dataset""")
    return


@app.cell
def _(fix_marimo_path, mo):
    cifar10_image = mo.image(
        fix_marimo_path("public/images/cifar_10.png"),
        width=800,
        caption="Encode samples that look like they are from cifar-10. From Figure 3 of 'Real numbers, data science and chaos: How to fit any dataset with a single parameter'.",
        style={"display": "block", "margin": "0 auto"}
    )
    cifar10_image
    return


@app.cell
def _(mo):
    mo.md(r"""This technique is incredibly verstile, able to achieve perfect acuracy across tons of different domains.""")
    return


@app.cell
def _(mo):
    mo.md(r"""## To the critics""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Yet at the same time, the one-parameter model is increidbly brittle. It exists as a crude hack, directly encoding the train set into a single parameter. Even simply shuffling the dataset will cause your model to break down because the decoder depends on the index $i$, not the sample $x_i$. It should be abundantly clear that the one-parameter model has no ability to generalize whatsoever. It would get a 0% on the private, heldout test set of ARCI-AGI-2.

    Two quick technical notes to the critics.

    **For the complexity theorists**, yes, this is cheating. We've violated the fundamental assumption of bounded-precision arithmetic. Most complexity problems assume we operate on a machine with an $\omega$-bit word-size. However, my one-parameter model assumes we can operate on a machine with infinite bit word-size.

    **For the deep learning theorists**, of course our one-parameter model can memorize any dataset. Our decoder contains $\sin$ which has an [infinite VC dimension](https://cseweb.ucsd.edu/classes/fa12/cse291-b/vcnotes.pdf), i.e. an unbounded hypothesis class, and is therefore infinitely expressive. It can learn anything. What is interesting about the one-parameter model is that it offers a tangible construction, not merely a claim of existence, for learning any dataset.
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""## Lessons""")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    A couple of key takeaways here.

    **Intelligence is not parameter count.**

    The existence of such a simple equation

    $$
    f_{\alpha, p}(i)
    =
    \sin^2 \Big(
        2^{i p} \arcsin(\sqrt{\alpha})
    \Big)
    $$

    with such powerful expressivity deomonstrates that model complexity cannot be determined by counting parameters alone. The one-parameter model exploits a often-overlooked fact: a single real-valued parameter can encode an unbounded amount of information by hiding complexity in its digits rather than in parameter count. In other words, don't automatically assume that a bigger model is a smarter model. Parameter count can be a poor proxy for intelligence.

    **Intelligence is compression.**

    To compress data, you must find regularities in it and finding regularities fundamentally requires intelligent pattern matching. If [intelligence is compression]((https://en.wikipedia.org/wiki/Hutter_Prize)), then our one-parameter model has all the intelligence of a phonebook. It achieves zero compression and is just a nice lookup table. It cannot discover patterns or extract structure. The one-parameter model simply stores the raw data and uses the precision $p$ as a tunable recovery knob.

    Real compression requires understanding. If you want to measure the complexity and expressivity of machine learning models, measure their compression. Use minimum description length or Kolmogorov complexity. These techniques capture whether a model has actually learned the underlying patterns. They cut through the illusion of parameter counts and reveal what the model truly understands.

    Prof. Albert Gu's paper [ARC-AGI without pretraining](https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html) actually does this right. They used a general-purpose compression algorithm to solve ARC-AGI without training on the test set. That's the real deal. Our one-parameter model is a degenerate version of the same idea.

    **Training on Test**

    Our one-parameter model takes the idea of "training on test" to the extreme: it encodes the entire test set directly into $\alpha$, achieving 100% accuracy while learning nothing. The one-parameter model is utterly impractical and, frankly, an absurd hack. But that's precisely the point: it is absurd to train on the test set just to get to the top of a leaderboard.

    Yet this is exactly what occurs in the AI community.

    Top AI labs quietly train on their test sets. The one-parameter model does it proudly.

    It is rumoured these labs have entire teams who generate synthetic dataset for the sole purpose of succeeding on a specific benchmark. This is overfitting taken to the extreme.

    **The ARC-AGI Benchmark**

    ARC-AGI was intentionally designed to resist overfitting. It uses a private test set for official scoring, making training on test impossible. (Our one-parameter model only trained on the public eval set.) Yet even ARC-AGI's organizers have raised concerns about test contamination creeping into modern AI development.
    """
    )
    return


@app.cell
def _(fix_marimo_path, mo):
    arc_agi_overfitting_image = mo.image(
        fix_marimo_path("public/images/arc_agi_overfitting.png"),
        width=800,
        caption="Mike Knoop on ARC-AGI overfitting. Retreived from https://arcprize.org/blog/arc-prize-2025-results-analysis on December 9th, 2025.",
        style={"display": "block", "margin": "0 auto"}
    )
    arc_agi_overfitting_image
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Yet there is a more fundamental point: many of the amazing approaches to the ARC-AGI competition seem to overfit to ARC-AGI itself. Researchers generate synthetic data specific to ARC-AGI and create abstractions unique to the grid structure of the competition. I doubht many of their techniques would generalize to other reasoning problems. How many of the innovative solutions to ARC-AGI have inspired downstream improvements in LLMs or other modes of intelligence? I would love to be wrong about this and hope these techniques prove to be good for more than just ARC-AGI's delightful puzzles and continue to drive innovation the broader field of AI.

    **Final Thoughts**

    To end, I'll leave with the same quote with which we started:

    > "When a measure becomes a target, it ceases to be a good measure" - Charles Goodhart
    """
    )
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    To cite this blog post
    ```md
    @online{Turok2025ARCAGI,
    	author = {Ethan Turok},
    	title = {I built a one-parameter model that gets 100% on ARC-AGI-2},
    	year = {2025},
    	url = {https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html},
    }
    ```
    """
    )
    return


if __name__ == "__main__":
    app.run()
